{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "733a3ee8",
   "metadata": {},
   "source": [
    "# Advanced Python: BYONN, Part II\n",
    "**B**uild **Y**our **O**wn **N**eural **N**etwork\n",
    "\n",
    "<center>\n",
    "<img src=\"../pictures/cajal_glial.jpg\" style=\"width:480px;height:626px;\">\n",
    "<br>\n",
    "<i>Glial cells of the cerebral cortex of a child (Santiago Ramón y Cajal, 1904)</i>\n",
    "</center>\n",
    "\n",
    "Recall that in the last session, we saw how to build a simple neural network using `Layer`s and `Module` objects in `pytorch`. Here, we will build a similar network to classify the MNIST dataset.\n",
    "\n",
    "References:\n",
    "- [Feed-Forward Neural Network (FFNN) — PyTorch](https://medium.com/@carlosrodrigo.coelho/feed-forward-neural-network-ffnn-pytorch-d5d9759f53d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1c38f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7de7e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training set\n",
    "mnist_train = MNIST(root='data/', train=True, download=True, \n",
    "                    transform=transforms.ToTensor()) \n",
    "                    # needs to transform img>tensor\n",
    "# load testing set\n",
    "mnist_test = MNIST(root='data/', train=False, download=True,\n",
    "                   transform=transforms.ToTensor()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f3e5a2",
   "metadata": {},
   "source": [
    "### Warm up:\n",
    "`mnist_train` and `mnist_test` are iterables (you can index them like a list). Each item is a tuple of (image, label) pair.\n",
    "\n",
    "1. Figure out what's the shape of the images.\n",
    "2. How many images are there in the training set? How about the testing set?\n",
    "3. How many classes are there in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9dd327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the following variables to match the dataset\n",
    "n_inputs = None\n",
    "n_classes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a52ecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# use pytorch DataLoaders to automatically load/feed data during train/test\n",
    "train_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f275d0",
   "metadata": {},
   "source": [
    "### Exercises:\n",
    "\n",
    "Define a neural network object from `pytorch` that consists of 1 hidden layer with 56 neurons and ReLU activation function. Importantly, the network should be able to take in images and output a vector of probabilities for each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353cab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out defintion for your neural network\n",
    "class NeuralNet():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d712e820",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 56\n",
    "\n",
    "# initialize instance    \n",
    "model = NeuralNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ac9f78",
   "metadata": {},
   "source": [
    "With the neural network defined, we can now train it on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef29391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "# makes sense to use cross entropy loss because we are training for discrete\n",
    "# category classifications (also could write our own loss function)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.0005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6221aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "# training loop\n",
    "n_total_steps = len(train_loader) # number of batches in training set\n",
    "\n",
    "# for storing lost history\n",
    "loss_hist = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = []\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # reshape images to (batch_size, input_size)\n",
    "        # eg: 100,1,28,28 -> 100,784\n",
    "        images = images.reshape(-1, 28**2)\n",
    "        labels = labels\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # saving the loss at current pass to log\n",
    "        epoch_loss.append(loss.detach().numpy()) # save value\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad() # set gradients to zero in every batch\n",
    "        loss.backward()     # backpropagation\n",
    "        optimizer.step()   # update weights\n",
    "\n",
    "        if (i+1) % 100 == 0: # print every 100 steps\n",
    "            print(f'epoch {epoch+1}/{n_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
    "    \n",
    "    # save mean loss of the epoch\n",
    "    loss_hist.append(np.mean(np.array(epoch_loss)))\n",
    "\n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0c96fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_hist, \"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa3da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "with torch.no_grad(): # we don't need gradients in the testing phase\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28**2)  # 100,1,28,28 -> 100,784\n",
    "        labels = labels          # 100,1 -> 100\n",
    "        outputs = model(images)  # 100,10\n",
    "\n",
    "        # value, index\n",
    "        _, predictions = torch.max(outputs, 1) # 1 is the dimension\n",
    "        n_samples += labels.shape[0] # number of samples in the current batch\n",
    "        n_correct += (predictions == labels).sum().item()  # number of correct predictions\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples  # accuracy\n",
    "    print(f'accuracy = {acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pni_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
